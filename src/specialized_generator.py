from google import genai
from typing import List, Dict
import os
from loguru import logger
import json
from datetime import datetime

class SpecializedPostGenerator:
    def __init__(self):
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError("GEMINI_API_KEY not found in environment variables")
            
        self.client = genai.Client(api_key=api_key)
        self.model_id = "gemini-2.5-pro"
        
        # D√©finir les domaines et leurs sp√©cialit√©s
        self.domains = {
            'frontend': {
                'name': 'D√©veloppement Frontend',
                'focus': 'interfaces utilisateur, frameworks JavaScript, CSS, exp√©rience utilisateur',
                'keywords': ['react', 'vue', 'angular', 'svelte', 'typescript', 'javascript', 'css', 'html', 'nextjs', 'nuxtjs']
            },
            'backend': {
                'name': 'D√©veloppement Backend',
                'focus': 'serveurs, APIs, bases de donn√©es, architecture logicielle',
                'keywords': ['nodejs', 'python', 'java', 'go', 'rust', 'php', 'django', 'fastapi', 'spring', 'api', 'database']
            },
            'ai': {
                'name': 'Intelligence Artificielle',
                'focus': 'machine learning, IA g√©n√©rative, mod√®les de langage, outils IA',
                'keywords': ['ai', 'ml', 'llm', 'gpt', 'claude', 'gemini', 'pytorch', 'tensorflow', 'openai', 'anthropic']
            },
            'general': {
                'name': 'Actualit√©s G√©n√©rales Tech',
                'focus': 'outils de d√©veloppement, DevOps, nouvelles technologies, industrie tech',
                'keywords': ['github', 'docker', 'kubernetes', 'devops', 'security', 'startup', 'tech industry']
            }
        }
        
    def generate_specialized_posts(self, articles: List[Dict]) -> List[Dict]:
        """G√©n√®re des posts sp√©cialis√©s pour chaque domaine ayant suffisamment d'articles"""
        specialized_posts = []
        
        # Organiser les articles par domaine
        articles_by_domain = self._organize_articles_by_domain(articles)
        
        for domain_key, domain_articles in articles_by_domain.items():
            # G√©n√©rer un post seulement si on a au moins 3 articles dans le domaine
            if len(domain_articles) >= 3:
                post = self._generate_domain_post(domain_key, domain_articles)
                if post:
                    specialized_posts.append(post)
                    logger.info(f"Generated specialized post for {domain_key} with {len(domain_articles)} articles")
            else:
                logger.info(f"Skipped {domain_key} - only {len(domain_articles)} articles (minimum 3 required)")
        
        return specialized_posts
    
    def generate_domain_post(self, articles: List[Dict], domain: str) -> Dict:
        """G√©n√®re un post pour un domaine sp√©cifique √† partir d'articles s√©lectionn√©s"""
        try:
            # Valider le domaine
            if domain not in self.domains:
                logger.error(f"Invalid domain: {domain}")
                return None
            
            # V√©rifier qu'on a au moins 2 articles
            if len(articles) < 2:
                logger.error(f"Not enough articles for generation: {len(articles)}")
                return None
            
            logger.info(f"Generating post for domain {domain} with {len(articles)} articles")
            
            # Utiliser la m√©thode priv√©e existante
            return self._generate_domain_post(domain, articles)
            
        except Exception as e:
            logger.error(f"Error in generate_domain_post: {e}")
            return None
    
    def _organize_articles_by_domain(self, articles: List[Dict]) -> Dict[str, List[Dict]]:
        """Organise les articles par domaine technique"""
        by_domain = {domain: [] for domain in self.domains.keys()}
        
        for article in articles:
            assigned_domain = self._determine_article_domain(article)
            by_domain[assigned_domain].append(article)
        
        # Trier chaque domaine par score de pertinence
        for domain in by_domain:
            by_domain[domain] = sorted(by_domain[domain], key=lambda x: x.get('relevance_score', 0), reverse=True)
        
        return by_domain
    
    def _determine_article_domain(self, article: Dict) -> str:
        """D√©termine le domaine principal d'un article"""
        # Utiliser le contenu complet si disponible, sinon le summary
        content = article.get('content', '') or article.get('summary', '')
        text_content = (article['title'] + ' ' + content).lower()
        category = article.get('category', 'general')
        
        # Scoring par domaine
        domain_scores = {}
        
        for domain_key, domain_info in self.domains.items():
            score = 0
            
            # Score bas√© sur les mots-cl√©s
            for keyword in domain_info['keywords']:
                if keyword in text_content:
                    score += 10
            
            # Score bas√© sur la cat√©gorie de la source
            if domain_key == 'ai' and category == 'ai':
                score += 20
            elif domain_key == 'backend' and category == 'backend':
                score += 20
            elif domain_key == 'frontend' and category == 'frontend':
                score += 20
            elif domain_key == 'general' and category in ['devtools', 'enterprise', 'devops']:
                score += 15
            
            domain_scores[domain_key] = score
        
        # Retourner le domaine avec le score le plus √©lev√©
        best_domain = max(domain_scores, key=domain_scores.get)
        
        # Si aucun domaine n'a de score significatif, classer en g√©n√©ral
        if domain_scores[best_domain] == 0:
            return 'general'
        
        return best_domain
    
    def _select_optimal_articles(self, articles: List[Dict], max_count: int = 10) -> List[Dict]:
        """S√©lectionne les articles optimaux pour g√©n√©ration de contenu de qualit√©"""
        if not articles:
            return []
        
        # Score de qualit√© pour la g√©n√©ration de contenu
        scored_articles = []
        
        for article in articles:
            content_score = 0
            
            # Score de base (pertinence technique)
            content_score += article.get('relevance_score', 0) * 0.6
            
            # Bonus pour diversit√© des sources
            content_score += self._calculate_source_diversity_bonus(article, articles)
            
            # Bonus pour contenu substantiel
            title_quality = self._evaluate_title_quality(article['title'])
            content_score += title_quality
            
            # Bonus pour r√©sum√© informatif
            # Utiliser le contenu complet pour √©valuer la qualit√©
            content = article.get('content', '') or article.get('summary', '')
            summary_quality = self._evaluate_summary_quality(content)
            content_score += summary_quality
            
            # Malus pour redondance technologique
            tech_redundancy = self._calculate_tech_redundancy(article, scored_articles)
            content_score -= tech_redundancy
            
            scored_articles.append({
                **article,
                'content_generation_score': content_score
            })
        
        # Trier par score de g√©n√©ration
        scored_articles.sort(key=lambda x: x['content_generation_score'], reverse=True)
        
        # S√©lection finale avec diversit√©
        selected = []
        used_sources = set()
        covered_technologies = set()
        
        for article in scored_articles:
            if len(selected) >= max_count:
                break
                
            source = article['source']
            
            # √âviter trop d'articles de la m√™me source
            if source in used_sources and len([a for a in selected if a['source'] == source]) >= 2:
                continue
            
            # Privil√©gier la diversit√© technologique
            article_techs = self._extract_technologies(article)
            if not article_techs.issubset(covered_technologies):
                selected.append(article)
                used_sources.add(source)
                covered_technologies.update(article_techs)
            elif len(selected) < max_count // 2:  # Autoriser quelques doublons au d√©but
                selected.append(article)
                used_sources.add(source)
        
        return selected[:max_count]
    
    def _calculate_source_diversity_bonus(self, article: Dict, all_articles: List[Dict]) -> float:
        """Calcule un bonus pour la diversit√© des sources"""
        source = article['source']
        same_source_count = len([a for a in all_articles if a['source'] == source])
        total_articles = len(all_articles)
        
        # Plus la source est rare, plus le bonus est √©lev√©
        rarity_bonus = max(0, 20 - (same_source_count / total_articles) * 40)
        return rarity_bonus
    
    def _evaluate_title_quality(self, title: str) -> float:
        """√âvalue la qualit√© d'un titre pour la g√©n√©ration"""
        score = 0
        
        # Longueur optimale
        length = len(title)
        if 30 <= length <= 80:
            score += 15
        elif 20 <= length <= 100:
            score += 10
        elif length < 15:
            score -= 10
        
        # Pr√©sence de mots-cl√©s techniques
        tech_indicators = ['api', 'framework', 'tool', 'new', 'update', 'release', 'feature', 'bug', 'fix', 'performance', 'security']
        for indicator in tech_indicators:
            if indicator.lower() in title.lower():
                score += 3
        
        # √âviter les titres clickbait
        clickbait_words = ['you won\'t believe', 'shocking', 'amazing', 'incredible', 'mind-blowing']
        for word in clickbait_words:
            if word.lower() in title.lower():
                score -= 5
        
        return score
    
    def _evaluate_summary_quality(self, summary: str) -> float:
        """√âvalue la qualit√© d'un r√©sum√©"""
        if not summary:
            return 0
        
        score = 0
        length = len(summary)
        
        # Longueur optimale pour r√©sum√©
        if 100 <= length <= 400:
            score += 10
        elif 50 <= length <= 500:
            score += 5
        elif length < 30:
            score -= 5
        
        # Pr√©sence d'informations techniques
        sentences = summary.split('.')
        if len(sentences) >= 2:
            score += 5
        
        return score
    
    def _calculate_tech_redundancy(self, article: Dict, existing_articles: List[Dict]) -> float:
        """Calcule la redondance technologique"""
        if not existing_articles:
            return 0
        
        article_techs = self._extract_technologies(article)
        
        redundancy = 0
        for existing in existing_articles:
            existing_techs = self._extract_technologies(existing)
            overlap = len(article_techs & existing_techs)
            
            if overlap > 0:
                redundancy += overlap * 2
        
        return min(redundancy, 20)  # Limiter le malus
    
    def _extract_technologies(self, article: Dict) -> set:
        """Extrait les technologies mentionn√©es dans un article"""
        # Utiliser le contenu complet si disponible
        content = article.get('content', '') or article.get('summary', '')
        text = (article['title'] + ' ' + content).lower()
        technologies = set()
        
        # Technologies communes
        all_techs = []
        for domain_info in self.domains.values():
            all_techs.extend(domain_info['keywords'])
        
        for tech in all_techs:
            if tech.lower() in text:
                technologies.add(tech.lower())
        
        return technologies
    
    def _generate_domain_sources(self, domain_key: str, articles: List[Dict]) -> str:
        """G√©n√®re une section sources pour un domaine sp√©cifique avec URLs (legacy)"""
        return self._generate_enhanced_sources(domain_key, articles)
    
    def _generate_domain_post(self, domain_key: str, articles: List[Dict]) -> Dict:
        """G√©n√®re un post sp√©cialis√© optimis√© pour LinkedIn"""
        domain_info = self.domains[domain_key]
        
        # S√©lection intelligente des articles pour g√©n√©ration optimale
        top_articles = self._select_optimal_articles(articles, max_count=10)
        
        # Analyser le contexte des articles pour un prompt adaptatif
        article_context = self._analyze_article_context(top_articles, domain_key)
        
        # Cr√©er le prompt optimis√©
        prompt = self._create_optimized_prompt(domain_key, domain_info, top_articles, article_context)
        
        try:
            response = self.client.models.generate_content(
                model=self.model_id,
                contents=prompt
            )
            
            content = response.text
            
            # Post-traitement pour LinkedIn
            optimized_content = self._optimize_for_linkedin(content, domain_key)
            
            # G√©n√©rer hashtags intelligents
            hashtags_str = self._generate_smart_hashtags(top_articles, domain_key)
            hashtags_list = hashtags_str.split() if hashtags_str else []
            
            # G√©n√©rer la section sources am√©lior√©e
            sources_section = self._generate_enhanced_sources(domain_key, top_articles)
            
            # Combiner tous les √©l√©ments
            full_content = optimized_content + "\n\n" + hashtags_str + "\n\n" + sources_section
            
            return {
                'content': full_content,
                'type': f'{domain_key}_specialized',
                'domain': domain_key,
                'domain_name': domain_info['name'],
                'source_articles': top_articles,
                'sources_count': len(set(article['source'] for article in top_articles)),
                'hashtags': hashtags_list,
                'article_context': article_context,
                'generated_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Error generating {domain_key} post: {e}")
            return None
    
    def _create_specialized_prompt(self, domain_key: str, domain_info: Dict, articles: List[Dict]) -> str:
        """Cr√©e un prompt sp√©cialis√© pour un domaine sp√©cifique"""
        
        articles_summary = "\n".join([
            f"{i+1}. {article['source']}: \"{article['title']}\""
            for i, article in enumerate(articles)
        ])
        
        # Technologies mentionn√©es dans les articles
        mentioned_techs = set()
        for article in articles:
            # Utiliser le contenu complet si disponible
            content = article.get('content', '') or article.get('summary', '')
            text = (article['title'] + ' ' + content).lower()
            for keyword in domain_info['keywords']:
                if keyword in text:
                    mentioned_techs.add(keyword.capitalize())
        
        tech_context = ', '.join(list(mentioned_techs)[:6]) if mentioned_techs else 'diverses technologies'
        
        # Prompt sp√©cialis√© par domaine
        domain_prompts = {
            'frontend': f"""
Tu es un journaliste sp√©cialis√© en d√©veloppement frontend. R√©dige un article de synth√®se sur les derni√®res actualit√©s du d√©veloppement d'interfaces utilisateur.

FOCUS: {domain_info['focus']}
TECHNOLOGIES ABORD√âES: {tech_context}

SOURCES ({len(articles)} articles):
{articles_summary}

CONSIGNES:
1. Ton journalistique sp√©cialis√© frontend
2. Focus sur les frameworks, outils UI, performance c√¥t√© client
3. Analyser l'impact pour les d√©veloppeurs frontend
4. Citer les sources entre parenth√®ses
5. 300-400 mots maximum
6. Aucune opinion, seulement des faits

STRUCTURE:
- Titre accrocheur sur les tendances frontend
- Lead: 1-2 d√©veloppements majeurs
- Analyse technique des √©volutions
- Implications pour les d√©veloppeurs frontend
- Conclusion sur l'√©cosyst√®me frontend

R√©dige l'article sp√©cialis√© frontend:
""",
            'backend': f"""
Tu es un journaliste sp√©cialis√© en d√©veloppement backend. R√©dige un article de synth√®se sur les derni√®res actualit√©s du d√©veloppement c√¥t√© serveur.

FOCUS: {domain_info['focus']}
TECHNOLOGIES ABORD√âES: {tech_context}

SOURCES ({len(articles)} articles):
{articles_summary}

CONSIGNES:
1. Ton journalistique sp√©cialis√© backend
2. Focus sur les APIs, bases de donn√©es, architecture serveur
3. Analyser l'impact pour les d√©veloppeurs backend
4. Citer les sources entre parenth√®ses
5. 300-400 mots maximum
6. Aucune opinion, seulement des faits

STRUCTURE:
- Titre accrocheur sur les √©volutions backend
- Lead: 1-2 d√©veloppements techniques majeurs
- Analyse des nouvelles approches/outils
- Implications pour l'architecture et les performances
- Conclusion sur l'√©cosyst√®me backend

R√©dige l'article sp√©cialis√© backend:
""",
            'ai': f"""
Tu es un journaliste sp√©cialis√© en intelligence artificielle. R√©dige un article de synth√®se sur les derni√®res actualit√©s en IA et machine learning.

FOCUS: {domain_info['focus']}
TECHNOLOGIES ABORD√âES: {tech_context}

SOURCES ({len(articles)} articles):
{articles_summary}

CONSIGNES:
1. Ton journalistique sp√©cialis√© IA
2. Focus sur les mod√®les, outils IA, applications pratiques
3. Analyser l'impact pour les d√©veloppeurs et l'industrie
4. Citer les sources entre parenth√®ses
5. 300-400 mots maximum
6. Aucune opinion, seulement des faits

STRUCTURE:
- Titre accrocheur sur les avanc√©es IA
- Lead: 1-2 d√©veloppements majeurs en IA
- Analyse des nouvelles capacit√©s/mod√®les
- Implications pour les d√©veloppeurs et les entreprises
- Conclusion sur l'√©volution de l'√©cosyst√®me IA

R√©dige l'article sp√©cialis√© IA:
""",
            'general': f"""
Tu es un journaliste sp√©cialis√© en actualit√©s technologiques. R√©dige un article de synth√®se sur les derni√®res actualit√©s g√©n√©rales du monde tech.

FOCUS: {domain_info['focus']}
DOMAINES COUVERTS: {tech_context}

SOURCES ({len(articles)} articles):
{articles_summary}

CONSIGNES:
1. Ton journalistique g√©n√©raliste tech
2. Focus sur les outils, tendances industrie, innovations
3. Analyser l'impact pour l'√©cosyst√®me de d√©veloppement
4. Citer les sources entre parenth√®ses
5. 300-400 mots maximum
6. Aucune opinion, seulement des faits

STRUCTURE:
- Titre accrocheur sur les tendances tech g√©n√©rales
- Lead: 1-2 d√©veloppements significatifs
- Analyse des nouvelles approches/outils
- Implications pour les d√©veloppeurs et l'industrie
- Conclusion sur l'√©volution du secteur tech

R√©dige l'article g√©n√©raliste tech:
"""
        }
        
        return domain_prompts.get(domain_key, domain_prompts['general'])
    
    def _analyze_article_context(self, articles: List[Dict], domain_key: str) -> Dict:
        """Analyse le contexte des articles pour adapter le prompt"""
        context = {
            'trending_technologies': [],
            'key_companies': [],
            'article_types': [],
            'urgency_level': 'normal',
            'technical_depth': 'medium',
            'content_insights': [],
            'temporal_context': 'current',
            'key_themes': []
        }
        
        # Analyser les technologies tendances
        tech_mentions = {}
        company_mentions = {}
        theme_mentions = {}
        
        companies = ['google', 'microsoft', 'openai', 'anthropic', 'meta', 'apple', 'amazon', 'netflix', 'uber', 'spotify', 'github', 'docker']
        
        # Th√®mes techniques importants
        themes = {
            'performance': ['performance', 'speed', 'optimization', 'faster', 'efficient'],
            'security': ['security', 'vulnerability', 'breach', 'attack', 'protection'],
            'scalability': ['scale', 'scalable', 'scalability', 'distributed', 'microservices'],
            'ai_integration': ['ai', 'ml', 'machine learning', 'artificial intelligence', 'llm'],
            'developer_experience': ['developer experience', 'dx', 'productivity', 'workflow', 'tools'],
            'open_source': ['open source', 'opensource', 'community', 'contribution', 'maintainer']
        }
        
        insights = []
        
        for article in articles:
            # Utiliser le contenu complet si disponible
            content = article.get('content', '') or article.get('summary', '')
            text = (article['title'] + ' ' + content).lower()
            
            # Extraire des insights cl√©s du contenu
            article_insights = self._extract_content_insights(content, article['title'])
            insights.extend(article_insights)
            
            # Technologies
            for tech in self.domains[domain_key]['keywords']:
                if tech.lower() in text:
                    tech_mentions[tech] = tech_mentions.get(tech, 0) + 1
            
            # Entreprises
            for company in companies:
                if company in text:
                    company_mentions[company] = company_mentions.get(company, 0) + 1
            
            # Th√®mes
            for theme_name, theme_keywords in themes.items():
                for keyword in theme_keywords:
                    if keyword in text:
                        theme_mentions[theme_name] = theme_mentions.get(theme_name, 0) + 1
            
            # Types d'articles avec plus de nuances
            if any(word in text for word in ['release', 'launch', 'announce', 'introduce']):
                context['article_types'].append('release')
            elif any(word in text for word in ['update', 'upgrade', 'improve', 'enhance']):
                context['article_types'].append('update')
            elif any(word in text for word in ['security', 'vulnerability', 'breach', 'exploit']):
                context['article_types'].append('security')
                context['urgency_level'] = 'high'
            elif any(word in text for word in ['breaking', 'urgent', 'critical', 'emergency']):
                context['urgency_level'] = 'high'
            elif any(word in text for word in ['tutorial', 'guide', 'how-to', 'getting started']):
                context['article_types'].append('educational')
            elif any(word in text for word in ['analysis', 'deep dive', 'investigation']):
                context['article_types'].append('analytical')
        
        # Analyse temporelle
        if any(word in ' '.join([a.get('content', '') + a['title'] for a in articles]).lower() 
               for word in ['today', 'this week', 'breaking', 'just announced']):
            context['temporal_context'] = 'breaking'
        elif any(word in ' '.join([a.get('content', '') + a['title'] for a in articles]).lower() 
                 for word in ['trend', 'evolution', 'future', 'upcoming']):
            context['temporal_context'] = 'trending'
        
        # Compilation des r√©sultats
        context['trending_technologies'] = sorted(tech_mentions.items(), key=lambda x: x[1], reverse=True)[:5]
        context['key_companies'] = sorted(company_mentions.items(), key=lambda x: x[1], reverse=True)[:3]
        context['key_themes'] = sorted(theme_mentions.items(), key=lambda x: x[1], reverse=True)[:4]
        context['content_insights'] = insights[:6]  # Top 6 insights
        
        # Niveau technique bas√© sur les sources et le contenu
        academic_sources = ['MIT CSAIL News', 'Stanford AI Lab', 'Papers With Code', 'IEEE Spectrum']
        technical_sources = ['Go Dev Blog', 'React Blog', 'Rust Blog', 'Python Official Blog']
        
        if any(article['source'] in academic_sources for article in articles):
            context['technical_depth'] = 'high'
        elif any(article['source'] in technical_sources for article in articles):
            context['technical_depth'] = 'technical'
        elif any(article['source'] in ['TechCrunch', 'VentureBeat'] for article in articles):
            context['technical_depth'] = 'accessible'
        
        return context
    
    def _extract_content_insights(self, content: str, title: str) -> List[str]:
        """Extrait des insights cl√©s du contenu complet"""
        if not content or len(content) < 200:
            return []
        
        insights = []
        
        # Patterns d'insights importants
        insight_patterns = [
            r'(\d+(?:\.\d+)?%)\s+(?:improvement|increase|decrease|faster|slower)',
            r'(?:new|latest|upcoming)\s+([a-zA-Z\s]+(?:version|release|update))',
            r'(?:supports?|introduces?|features?)\s+([a-zA-Z\s]+(?:API|framework|library|tool))',
            r'(?:significantly|dramatically|substantially)\s+([a-zA-Z\s]+)',
            r'(?:compared to|versus|vs\.?)\s+([a-zA-Z\s]+)',
        ]
        
        import re
        
        for pattern in insight_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches[:2]:  # Max 2 par pattern
                if isinstance(match, tuple):
                    match = ' '.join(match)
                if len(match) > 10 and len(match) < 80:
                    insights.append(match.strip())
        
        return insights[:3]  # Max 3 insights par article
    
    def _create_optimized_prompt(self, domain_key: str, domain_info: Dict, articles: List[Dict], context: Dict) -> str:
        """Cr√©e un prompt optimis√© bas√© sur le contexte des articles"""
        
        # Construction dynamique du r√©sum√© des articles
        articles_summary = self._build_contextual_summary(articles, context)
        
        # Technologies tendances pour ce batch
        trending_techs = [tech for tech, _ in context['trending_technologies']]
        tech_focus = ', '.join(trending_techs[:4]) if trending_techs else 'diverses technologies'
        
        # Entreprises cl√©s
        key_companies = [comp for comp, _ in context['key_companies']]
        company_context = f" (notamment {', '.join(key_companies[:2])})" if key_companies else ""
        
        # Th√®mes cl√©s
        key_themes = [theme for theme, _ in context['key_themes']]
        themes_context = f"Th√®mes dominants: {', '.join(key_themes[:3])}" if key_themes else ""
        
        # Insights du contenu
        content_insights = context.get('content_insights', [])
        insights_context = f"Insights cl√©s: {' ‚Ä¢ '.join(content_insights[:3])}" if content_insights else ""
        
        # Adapter le ton selon l'urgence et le contexte temporel
        urgency_tone = {
            'high': 'URGENT - ',
            'normal': '',
            'low': ''
        }.get(context['urgency_level'], '')
        
        temporal_indicators = {
            'breaking': 'üö® BREAKING: ',
            'trending': 'üìà TRENDING: ',
            'current': ''
        }.get(context.get('temporal_context', 'current'), '')
        
        # Prompts optimis√©s par domaine
        optimized_prompts = {
            'frontend': f"""
Tu es un expert en d√©veloppement frontend reconnu sur LinkedIn. R√©dige un post engageant sur les derni√®res actualit√©s frontend.

üéØ CONTEXTE ENRICHI:
‚Ä¢ Technologies tendances: {tech_focus}
‚Ä¢ Entreprises actives: {', '.join(key_companies) if key_companies else '√©cosyst√®me global'}
‚Ä¢ {themes_context}
‚Ä¢ {insights_context}
‚Ä¢ Niveau technique: {context['technical_depth']}
‚Ä¢ Urgence: {context['urgency_level']} | Temporalit√©: {context.get('temporal_context', 'current')}

üì∞ SOURCES ANALYS√âES ({len(articles)} articles):
{articles_summary}

‚úÖ CONSIGNES LINKEDIN OPTIMIS√âES:
1. Ton professionnel mais accessible, adapt√© aux d√©veloppeurs frontend
2. Utiliser des √©mojis de fa√ßon strat√©gique (2-3 maximum)
3. Structure avec des bullet points pour la lisibilit√©
4. Inclure une question engageante sp√©cifique au contenu analys√©
5. Mentionner l'impact concret pour les √©quipes frontend
6. Citer les sources avec √©l√©gance: "selon [Source]"
7. 280-350 mots pour optimiser l'engagement LinkedIn
8. Utiliser les insights extraits pour enrichir le contenu
9. Adapter le ton √† la temporalit√© des news

üèóÔ∏è STRUCTURE OPTIMIS√âE:
‚Ä¢ {temporal_indicators}{urgency_tone}Accroche percutante bas√©e sur les insights r√©els
‚Ä¢ Context: Pourquoi c'est important maintenant (lien avec les th√®mes identifi√©s)
‚Ä¢ üî• Points cl√©s (2-3 d√©veloppements majeurs avec extraits concrets)
‚Ä¢ üí° Impact pratique pour les d√©veloppeurs (bas√© sur les insights)
‚Ä¢ ‚ùì Question d'engagement sp√©cifique au contenu analys√©

üìù STYLE LINKEDIN ADAPTATIF:
- Phrases courtes et percutantes
- Utiliser les insights extraits pour donner des exemples concrets
- Ton informatif mais enthousiasmant
- Focus sur la valeur ajout√©e pour la communaut√© dev
- Adapter l'urgence du ton selon le contexte temporel

üéØ √âL√âMENTS √Ä INT√âGRER:
- Utiliser les insights extraits comme exemples concrets
- Mentionner les th√®mes dominants identifi√©s
- Adapter le call-to-action selon le type d'articles analys√©s

R√©dige le post LinkedIn frontend optimis√©:
""",
            
            'backend': f"""
Tu es un architecte backend senior influent sur LinkedIn. Cr√©e un post captivant sur l'actualit√© backend/infrastructure.

üéØ CONTEXTE TECHNIQUE ENRICHI:
‚Ä¢ Technologies phares: {tech_focus}
‚Ä¢ Acteurs majeurs: {', '.join(key_companies) if key_companies else '√©cosyst√®me complet'}{company_context}
‚Ä¢ {themes_context}
‚Ä¢ {insights_context}
‚Ä¢ Complexit√©: {context['technical_depth']}
‚Ä¢ Priorit√©: {context['urgency_level']} | Temporalit√©: {context.get('temporal_context', 'current')}

üìä SOURCES ANALYS√âES ({len(articles)} articles):
{articles_summary}

‚úÖ CONSIGNES LINKEDIN PRO OPTIMIS√âES:
1. Expertise technique mais accessible aux lead devs
2. √âmojis techniques pertinents (‚ö°üîßüöÄ) avec parcimonie
3. Structure claire avec sections d√©finies
4. Angle "impact business" pour toucher les d√©cideurs
5. Implications concr√®tes pour l'architecture et les √©quipes
6. Citations √©l√©gantes: "d'apr√®s [Source]" ou "selon [Source]"
7. 300-380 mots pour maximiser l'engagement professionnel
8. Utiliser les insights extraits pour donner des m√©triques/exemples concrets
9. Adapter le ton √† l'urgence et la temporalit√© des d√©veloppements

üèõÔ∏è ARCHITECTURE DU POST:
‚Ä¢ {temporal_indicators}{urgency_tone}Hook technique percutant bas√© sur les insights r√©els
‚Ä¢ Contexte: Enjeux actuels pour les √©quipes backend (lien avec th√®mes identifi√©s)
‚Ä¢ ‚ö° D√©veloppements cl√©s (2-3 points avec impact technique et m√©triques)
‚Ä¢ üîß Implications pratiques (performance, scalabilit√©, s√©curit√©) avec exemples concrets
‚Ä¢ üí≠ Question strat√©gique sp√©cifique au contenu analys√©

üìà ANGLE LINKEDIN ADAPTATIF:
- Vocabulaire technique pr√©cis mais accessible
- Focus sur ROI et impact m√©tier avec donn√©es concr√®tes
- Ton d'expert consultant adapt√© √† la temporalit√©
- Valeur actionnable pour les professionnels
- Utiliser les insights pour donner des exemples chiffr√©s

üéØ √âL√âMENTS TECHNIQUES √Ä INT√âGRER:
- Utiliser les insights extraits pour donner des m√©triques de performance
- Mentionner les th√®mes dominants avec implications architecturales
- Adapter le niveau d'urgence selon le contexte temporel
- Inclure des implications concr√®tes pour les √©quipes

Cr√©e le post LinkedIn backend expert:
""",
            
            'ai': f"""
Tu es un expert IA/ML reconnu sur LinkedIn. Compose un post viral sur l'actualit√© intelligence artificielle.

üß† CONTEXTE:
‚Ä¢ Technologies IA: {tech_focus}
‚Ä¢ Leaders du secteur: {', '.join(key_companies) if key_companies else '√©cosyst√®me IA global'}
‚Ä¢ Niveau: {context['technical_depth']}
‚Ä¢ Impact: {context['urgency_level']}

ü§ñ SOURCES EXPERT ({len(articles)} articles):
{articles_summary}

‚úÖ OPTIMISATION LINKEDIN IA:
1. Ton visionnaire mais ancr√© dans le r√©el
2. √âmojis IA strat√©giques (ü§ñüß†‚ö°) pour l'identit√© visuelle
3. Structure narrative captivante
4. √âquilibre technique/business pour audience mixte
5. Impact sur l'industrie ET les d√©veloppeurs
6. Sources cr√©dibles: "selon [Source]" avec autorit√©
7. 320-400 mots pour contenu premium IA
8. √âviter le hype, privil√©gier les faits

üöÄ BLUEPRINT VIRAL:
‚Ä¢ {urgency_tone}Accroche disruptive (√©volution majeure + √©moji)
‚Ä¢ Vision: Ce que √ßa change pour l'industrie tech
‚Ä¢ üß† Innovations cl√©s (2-3 avanc√©es concr√®tes)
‚Ä¢ üíº Impact m√©tier (productivit√©, nouveaux usages)
‚Ä¢ üîÆ Question prospective pour g√©n√©rer l'engagement

üéØ STYLE THOUGHT LEADER:
- Vocabulaire IA pr√©cis sans √™tre herm√©tique
- Perspective industrie + implications pratiques
- Ton d'expert consultant en transformation
- Contenu r√©f√©rence pour la communaut√© IA

Produis le post LinkedIn IA thought leader:
""",
            
            'general': f"""
Tu es un tech leader influent sur LinkedIn. Cr√©e un post engageant sur les tendances tech transversales.

üí° CONTEXTE MULTI-DOMAINES:
‚Ä¢ Technologies √©mergentes: {tech_focus}
‚Ä¢ √âcosyst√®me: {', '.join(key_companies) if key_companies else 'industrie tech globale'}
‚Ä¢ Audience: {context['technical_depth']} (mixed technical/business)
‚Ä¢ Momentum: {context['urgency_level']}

üì° SOURCES DIVERSIFI√âES ({len(articles)} articles):
{articles_summary}

‚úÖ STRAT√âGIE LINKEDIN CROSS-TECH:
1. Ton de tech leader accessible √† tous profils
2. √âmojis universels tech (üíªüöÄ‚ö°) pour large audience
3. Structure claire pour professionnels occup√©s
4. Angle transformation digitale et innovation
5. Impact sur l'√©cosyst√®me tech global
6. Cr√©dibilit√©: "selon [Source]" avec expertise
7. 300-370 mots pour engagement optimal cross-audience
8. Vision holistique de l'√©volution tech

üåü TEMPLATE CROSS-IMPACT:
‚Ä¢ {urgency_tone}Vision macro (tendance industry-wide)
‚Ä¢ Contexte: Pourquoi c'est un tournant pour la tech
‚Ä¢ üöÄ √âvolutions marquantes (2-3 d√©veloppements transversaux)
‚Ä¢ üíº Impact √©cosyst√®me (startups, scale-ups, enterprise)
‚Ä¢ ü§î Question strat√©gique pour tous les profils tech

üé™ POSITIONNEMENT THOUGHT LEADER:
- Perspective 360¬∞ sur l'innovation tech
- Ton de guide pour les d√©cisions strat√©giques
- Contenu f√©d√©rateur pour la communaut√© tech
- Valeur ajout√©e pour tous les m√©tiers du num√©rique

Cr√©e le post LinkedIn tech leader:
"""
        }
        
        return optimized_prompts.get(domain_key, optimized_prompts['general'])
    
    def _build_contextual_summary(self, articles: List[Dict], context: Dict) -> str:
        """Construit un r√©sum√© contextuel enrichi des articles avec LLM"""
        summary_lines = []
        
        # G√©n√©rer tous les summaries en une fois pour optimiser les performances
        articles_with_summaries = self._generate_batch_summaries(articles)
        
        for i, article in enumerate(articles_with_summaries, 1):
            source = article['source']
            title = article['title']
            
            # Raccourcir le titre si n√©cessaire
            if len(title) > 70:
                title = title[:67] + "..."
            
            # Utiliser le summary AI g√©n√©r√©
            ai_summary = article.get('ai_summary', '')
            
            # Ajouter des indicateurs de contexte am√©lior√©s
            indicators = []
            content = article.get('content', '') or article.get('summary', '')
            text = (title + ' ' + content).lower()
            
            if any(word in text for word in ['release', 'launch', 'announce']):
                indicators.append('üöÄ')
            elif any(word in text for word in ['update', 'security', 'vulnerability']):
                indicators.append('üîí')
            elif any(word in text for word in ['performance', 'speed', 'optimization']):
                indicators.append('‚ö°')
            elif any(word in text for word in ['breaking', 'urgent', 'critical']):
                indicators.append('üö®')
            elif any(word in text for word in ['tutorial', 'guide', 'how-to']):
                indicators.append('üìö')
            
            indicator = ''.join(indicators[:1])  # Max 1 emoji
            
            # Format enrichi avec summary AI
            base_line = f"{i}. {indicator} {source}: \"{title}\""
            if ai_summary and len(ai_summary) > 20:
                base_line += f"\n   ‚Üí {ai_summary}"
            
            summary_lines.append(base_line)
        
        return "\n".join(summary_lines)
    
    def _generate_batch_summaries(self, articles: List[Dict]) -> List[Dict]:
        """G√©n√®re des summaries pour tous les articles de mani√®re optimis√©e"""
        enhanced_articles = []
        
        for article in articles:
            enhanced_article = article.copy()
            
            # G√©n√©rer le summary AI
            content = article.get('content', '') or article.get('summary', '')
            ai_summary = self._generate_article_summary(content, article['title'], article['source'])
            enhanced_article['ai_summary'] = ai_summary
            
            enhanced_articles.append(enhanced_article)
            
            # Log du progr√®s
            logger.info(f"Generated summary for: {article['title'][:50]}...")
        
        return enhanced_articles
    
    def _generate_article_summary(self, content: str, title: str, source: str) -> str:
        """G√©n√®re un r√©sum√© intelligent d'un article avec le LLM"""
        if not content or len(content) < 100:
            return ""
        
        try:
            # Limiter le contenu pour √©viter des co√ªts excessifs
            limited_content = content[:3000] if len(content) > 3000 else content
            
            summary_prompt = f"""
Analyse cet article technique et g√©n√®re un r√©sum√© de 1-2 phrases (max 120 caract√®res) qui capture l'essentiel pour un d√©veloppeur.

ARTICLE: "{title}"
SOURCE: {source}
CONTENU: {limited_content}

CONSIGNES:
- 1-2 phrases maximum
- Focus sur l'impact technique concret
- Langage accessible aux d√©veloppeurs
- √âviter le jargon marketing
- Mettre l'accent sur ce qui change concr√®tement

R√âSUM√â:"""

            response = self.client.models.generate_content(
                model=self.model_id,
                contents=summary_prompt
            )
            
            summary = response.text.strip()
            
            # Nettoyer et limiter la taille
            if len(summary) > 120:
                summary = summary[:117] + "..."
            
            # Supprimer les guillemets et autres caract√®res ind√©sirables
            summary = summary.replace('"', '').replace('¬´', '').replace('¬ª', '').strip()
            
            return summary
            
        except Exception as e:
            logger.debug(f"Error generating summary for article: {e}")
            # Fallback vers l'extraction manuelle
            return self._extract_key_excerpt(content, title)
    
    def _extract_key_excerpt(self, content: str, title: str) -> str:
        """Extrait un extrait cl√© pertinent du contenu"""
        if not content or len(content) < 100:
            return ""
        
        # Diviser en phrases
        sentences = content.split('.')
        key_sentences = []
        
        # Mots-cl√©s indicateurs d'importance
        importance_keywords = [
            'announce', 'release', 'launch', 'introduce', 'new', 'update',
            'improve', 'performance', 'security', 'feature', 'version',
            'significant', 'major', 'important', 'breakthrough', 'innovative'
        ]
        
        for sentence in sentences[:10]:  # Examiner les 10 premi√®res phrases
            sentence = sentence.strip()
            if len(sentence) > 30 and len(sentence) < 150:
                # Scorer la pertinence
                score = 0
                sentence_lower = sentence.lower()
                
                # Bonus pour mots-cl√©s d'importance
                for keyword in importance_keywords:
                    if keyword in sentence_lower:
                        score += 2
                
                # Bonus pour contenu technique
                if any(word in sentence_lower for word in ['api', 'framework', 'library', 'tool', 'platform']):
                    score += 1
                
                # √âviter les phrases trop g√©n√©riques
                if any(word in sentence_lower for word in ['according to', 'in conclusion', 'furthermore']):
                    score -= 1
                
                if score > 0:
                    key_sentences.append((sentence, score))
        
        if key_sentences:
            # Retourner la phrase avec le meilleur score
            best_sentence = max(key_sentences, key=lambda x: x[1])[0]
            # Nettoyer et raccourcir si n√©cessaire
            if len(best_sentence) > 120:
                best_sentence = best_sentence[:117] + "..."
            return best_sentence
        
        return ""
    
    def _optimize_for_linkedin(self, content: str, domain_key: str) -> str:
        """Optimise le contenu pour LinkedIn"""
        # Nettoyage de base
        optimized = content.strip()
        
        # Ajouter des sauts de ligne pour la lisibilit√© LinkedIn
        # Remplacer les longs paragraphes par des sections plus courtes
        paragraphs = optimized.split('\n\n')
        readable_paragraphs = []
        
        for paragraph in paragraphs:
            if len(paragraph) > 300:  # Paragraphe trop long
                # Diviser aux phrases
                sentences = paragraph.split('. ')
                current_chunk = ""
                
                for sentence in sentences:
                    if len(current_chunk + sentence) < 200:
                        current_chunk += sentence + ". "
                    else:
                        if current_chunk:
                            readable_paragraphs.append(current_chunk.strip())
                        current_chunk = sentence + ". "
                
                if current_chunk:
                    readable_paragraphs.append(current_chunk.strip())
            else:
                readable_paragraphs.append(paragraph)
        
        return "\n\n".join(readable_paragraphs)
    
    def _generate_smart_hashtags(self, articles: List[Dict], domain_key: str) -> str:
        """G√©n√®re des hashtags intelligents bas√©s sur le contenu"""
        hashtags = set()
        
        # Hashtags de base par domaine
        base_hashtags = {
            'frontend': ['#Frontend', '#JavaScript', '#WebDev', '#React', '#CSS'],
            'backend': ['#Backend', '#API', '#DevOps', '#CloudComputing', '#Microservices'],
            'ai': ['#AI', '#MachineLearning', '#DeepLearning', '#LLM', '#Innovation'],
            'general': ['#Tech', '#Development', '#Innovation', '#DigitalTransformation']
        }
        
        hashtags.update(base_hashtags.get(domain_key, base_hashtags['general'])[:3])
        
        # Hashtags dynamiques bas√©s sur les technologies mentionn√©es
        tech_hashtags = {
            'react': '#React', 'vue': '#VueJS', 'angular': '#Angular',
            'nodejs': '#NodeJS', 'python': '#Python', 'go': '#Golang',
            'rust': '#RustLang', 'typescript': '#TypeScript',
            'kubernetes': '#Kubernetes', 'docker': '#Docker',
            'openai': '#OpenAI', 'anthropic': '#Anthropic',
            'security': '#CyberSecurity', 'performance': '#Performance'
        }
        
        for article in articles:
            # Utiliser le contenu complet si disponible
            content = article.get('content', '') or article.get('summary', '')
            text = (article['title'] + ' ' + content).lower()
            for tech, hashtag in tech_hashtags.items():
                if tech in text and len(hashtags) < 8:
                    hashtags.add(hashtag)
        
        # Hashtags trending/g√©n√©riques
        trending = ['#TechNews', '#DeveloperCommunity', '#SoftwareEngineering']
        for tag in trending:
            if len(hashtags) < 10:
                hashtags.add(tag)
            else:
                break
        
        return ' '.join(sorted(list(hashtags)[:8]))  # Max 8 hashtags
    
    def _generate_enhanced_sources(self, domain_key: str, articles: List[Dict]) -> str:
        """G√©n√®re une section sources optimis√©e pour LinkedIn"""
        domain_name = self.domains[domain_key]['name']
        
        # Header plus engageant
        sources_header = f"üìö **SOURCES {domain_name.upper()} ANALYS√âES**\n"
        
        # Regrouper par type de source pour plus de clart√©
        source_groups = {
            'Officielles': [],
            'Acad√©miques': [],
            'M√©dias Tech': [],
            'Communaut√©': []
        }
        
        # Classification des sources
        official_sources = {'React Blog', 'Node.js Blog', 'Go Dev Blog', 'Rust Blog', 'OpenAI Blog', 'Google AI Blog'}
        academic_sources = {'MIT CSAIL News', 'Stanford AI Lab', 'IEEE Spectrum', 'Papers With Code'}
        tech_media = {'TechCrunch', 'Ars Technica', 'MIT Technology Review', 'VentureBeat'}
        
        for article in articles:
            source = article['source']
            title = article['title']
            url = article.get('url', '')
            
            # Raccourcir le titre
            if len(title) > 50:
                title = title[:47] + "..."
            
            source_info = {'source': source, 'title': title, 'url': url}
            
            if source in official_sources:
                source_groups['Officielles'].append(source_info)
            elif source in academic_sources:
                source_groups['Acad√©miques'].append(source_info)
            elif source in tech_media:
                source_groups['M√©dias Tech'].append(source_info)
            else:
                source_groups['Communaut√©'].append(source_info)
        
        # Construire la section optimis√©e
        sources_section = sources_header + "\n"
        
        for group_name, group_articles in source_groups.items():
            if group_articles:
                # Ic√¥nes par type
                icons = {
                    'Officielles': 'üè¢',
                    'Acad√©miques': 'üéì', 
                    'M√©dias Tech': 'üì∞',
                    'Communaut√©': 'üë•'
                }
                
                sources_section += f"{icons[group_name]} **{group_name}:**\n"
                
                for i, article_info in enumerate(group_articles[:3], 1):  # Max 3 par groupe
                    source = article_info['source']
                    title = article_info['title']
                    url = article_info['url']
                    
                    if url:
                        sources_section += f"‚Ä¢ [{source}]({url}) - {title}\n"
                    else:
                        sources_section += f"‚Ä¢ **{source}** - {title}\n"
                
                sources_section += "\n"
        
        # Footer avec m√©tadonn√©es
        total_sources = len(set(article['source'] for article in articles))
        sources_section += f"_Analyse bas√©e sur {len(articles)} articles de {total_sources} sources fiables_"
        
        return sources_section.strip()
    
    def get_domain_distribution(self, articles: List[Dict]) -> Dict:
        """Retourne la distribution des articles par domaine"""
        by_domain = self._organize_articles_by_domain(articles)
        
        distribution = {}
        total = len(articles)
        
        for domain_key, domain_articles in by_domain.items():
            count = len(domain_articles)
            percentage = round((count / total) * 100, 1) if total > 0 else 0
            
            distribution[domain_key] = {
                'name': self.domains[domain_key]['name'],
                'count': count,
                'percentage': percentage,
                'can_generate': count >= 3
            }
        
        return distribution
    
    def generate_article_variations(self, articles: List[Dict], count: int = 1) -> List[Dict]:
        """Interface de compatibilit√© avec l'ancien syst√®me"""
        return self.generate_specialized_posts(articles)